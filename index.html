<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
		<meta name="description" content="">
		<meta name="author" content="">
		<link rel="icon" href="favicon.ico">

		<title>Dalong's Home</title>

		<!-- Bootstrap core CSS -->
		<link href="css/bootstrap.min.css" rel="stylesheet">
		<!-- Bootstrap theme -->
		<link href="css/bootstrap-theme.min.css" rel="stylesheet">
		<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
		<link href="assets/css/ie10-viewport-bug-workaround.css" rel="stylesheet">

		<!-- Custom styles for this template -->
		<link href="css/theme.css" rel="stylesheet">

		<!-- Just for debugging purposes. Don't actually copy these 2 lines! -->
		<!--[if lt IE 9]><script src="../../assets/js/ie8-responsive-file-warning.js"></script><![endif]-->
		<script src="assets/js/ie-emulation-modes-warning.js"></script>

		<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
		<!--[if lt IE 9]>
		  <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
		  <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
		<![endif]-->
	</head>
	
	<body>
		<div class="container">
			<div class="row clearfix">
				<div class="col-md-12 column">
					<nav class="navbar navbar-default navbar-fixed-top" role="navigation">
						<!-- navigation bar -->
						<div class="navbar-header">
							 <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1"> <span class="sr-only">Toggle navigation</span><span class="icon-bar"></span><span class="icon-bar"></span><span class="icon-bar"></span></button> <a class="navbar-brand" href="#">AboutMe</a>
						</div>
						
						<div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
							<ul class="nav navbar-nav">
								<li>
									 <a href="#">CV</a>
								</li>
								<!--<li>
									 <a href="#">BOLG</a>
								</li> -->
							</ul>
							<form class="navbar-form navbar-left" role="search">
								<div class="form-group">
									<input type="text" class="form-control" />
								</div> <button type="submit" class="btn btn-default">Search</button>
							</form>
						</div>
						
					</nav>
					<div class="row clearfix">
						<div class="col-md-2 column">
							<img alt="140x140" src="static/photo.JPG" style="width: 140px; height: 70px; margin-top: 60px; margin-bottom: 30px;"/>
							<p class="text-left lead"> <strong>Ruilong Li</strong><br /><strong>李瑞龙</strong> </p>
							<address> 
								<strong>Tsinghua University </strong><br /> 
								<strong>Beijing, China</strong><br />
								<br /><br /> 
								<a href="https://github.com/liruilong940607">GitHub</a><br /> 
								<a href="https://scholar.google.com.hk/citations?user=Pz8G-koAAAAJ&hl=en">Google Scholar</a><br /> 
								<small>li-rl16@mails.tsinghua.edu.cn</small><br />
							</address>
						</div>

						<div class="col-md-9 column">
							<!-- self intro -->
							<p class="text-left lead">
								I'm now a second-year master candidate in the <a href="http://cg.cs.tsinghua.edu.cn/">Graphics and Geometric Computing Group</a> of Tsinghua University. I am now pursuing a PHD after my graduation at June 2019. My research interests are focus on Computer Vision and Machine Learning. 
							</p>

							<!-- education -->
							<div class="page-header">
							<h3> Education </h3>
							</div>
							<div class="row">
							<ul>
							<li> <strong> 2016 - now </strong> Tsinghua University, Beijing, China
							<ul>
							<li>Master Candidate of Computer Science and Technology
							</ul>
							<li> <strong> 2012 - 2016 </strong> Tsinghua University, Beijing, China
							<ul>
							<li>Bachelor of Physics and Mathmatics
							</ul>
							</ul>
							</div>

							<!-- intern -->
							<div class="page-header">
							<h3> Intern Experience </h3>
							</div>
							<div class="row">
							<ul>
							<li> <strong> 2016.6 - 2016.9 </strong> <a href="http://www.deepglint.com/">DeepGlint, Beijing, China</a>
							<ul>
							<li>Computer Vision Engineer
							<li>Focus on Image/Video matching algorithm and tracking algorithm.
							</ul>
							<li> <strong> 2017.6 - 2016.8 </strong> <a href="http://www.toutiao.com/about/">Bytedance, Beijing, China</a>
							<ul>
							<li>Computer Vision Engineer
							<li>Focus on Semantic Segmentation Using CNN.
							</ul>
							</ul>
							</div>

							<!-- papers -->
							<div class="page-header">
							<h3> Research Experience </h3>
							</div>
							<!-- 4 -->
							<div class="media">
							<a class="pull-left">
							<img class="media-object" src="static/image_pose2seg.png" width="150px" height="150px">
							</a>
							<div class="media-body">
							<p class="media-heading">
							<strong>Pose2Seg: Human Instance Segmentation Without Detection</strong><br>
							<strong>Ruilong Li</strong>, Xin Dong, Zixi Cai, Dingcheng Yang, Haozhi Huang, Song-Hai Zhang, Paul L. Rosin, Shi-Min Hu, <i>arXiv 2017</i>
							<a target="_blank" href="https://arxiv.org/abs/1803.10683">[Paper]</a>
							<!-- <a target="_blank" href="">[Code]</a> -->
							</p>
							<p class="abstract-text">
							The general method of image instance segmentation is to perform the object detection first, and then segment the object from the detection bounding-box. More recently, deep learning methods like Mask R-CNN perform them jointly. However, little research takes into account the uniqueness of the "1human" category, which can be well defined by the pose skeleton. In this paper, we present a brand new pose-based instance segmentation framework for humans which separates instances based on human pose, not proposal region detection. We demonstrate that our pose-based framework can achieve similar accuracy to the detection-based approach, and can moreover better handle occlusion, which is the most challenging problem in the detection-based framework.
							</p>
							</div>
							</div>
							<!-- 3 -->
							<div class="media">
							<a class="pull-left">
							<img class="media-object" src="static/TMM-2017-VideoDistractor.jpg" width="150px" height="120px">
							</a>
							<div class="media-body">
							<p class="media-heading">
							<strong>Detecting and Removing Visual Distractors for Video Aesthetic Enhancement</strong><br>
							Fang-Lue Zhang, Xian Wu, <strong>RuiLong Li</strong>, Zhao-Heng Zheng, Jue Wang, Shi-Min Hu, <i>IEEE Transactions on Multimedia 2018</i>
							<a target="_blank" href="http://cg.cs.tsinghua.edu.cn/papers/TMM-2017-VideoDistractor.pdf">[Paper]</a> 
							<!-- <a target="_blank" href="">[Code]</a> -->
							</p>
							<p class="abstract-text">
							Personal videos often contain visual distractors, i.e. objects that are accidentally captured that can distract viewers from focusing on the main subjects. We propose a method to automatically detect and localize these distractors, by learning from a manually-labeled dataset. To achieve spatially- and temporally-coherent detection, we propose to extract features at the Temporal-Superpixel (TSP) level in a traditional SVM-based learning framework. We have also experimented with end-to-end learning with Convolutional Neural Networks (CNNs), which achieve slightly higher performance. The classification result is further refined in a post-processing step based on graph-cut optimization. Experimental results show that our method achieves an accuracy of 81% and a recall of 86%. We demonstrate several ways to remove the detected distractors to improve the video quality, including video hole filling; video frame replacement; and camera path re-planning.
							</p>
							</div>
							</div>
							<!-- 2 -->
							<div class="media">
							<a class="pull-left">
							<img class="media-object" src="static/image_portrait.png" width="150px" height="100px">
							</a>
							<div class="media-body">
							<p class="media-heading">
							<strong>Fast Portrait Automatic Segmentation with Coarse-to-Fine CNNs</strong><br>
							Xijin Zhang, <strong>Ruilong Li</strong>, Song-Hai Zhang, <i>Visual Computing for Industry, Biomedicine and Art, 2017</i>
							<a target="_blank" href="http://www.cnki.com.cn/Article/CJFDTotal-CADD201702006.htm">[Paper]</a>
							<!-- <a target="_blank" href="">[Code]</a> -->
							</p>
							<p class="abstract-text">
							In this paper, we propose a coarse-to-fine convolutional network framework designed with problem specific knowledge for fast automatic portrait segmentation. We built up a dataset of 7100 portrait images which are frames from personal live show videos. The proposed network includes a coarse network which can learn  global information and a fine network which  utilizes  local information to refine the coarse output. Additionally, an auxiliary contour loss is introduced to help training the coarse network. The proposed framework shows higher accuracy than the widely-used fully convolutional network. With light-weight post-processing, the predicted foreground mask can be used in real-time portrait video editing tasks such as background replacement.
							</p>
							</div>
							</div>
							<!-- 1 -->
							<div class="media">
							<a class="pull-left">
							<img class="media-object" src="static/image_cartoon.png" width="150px" height="150px">
							</a>
							<div class="media-body">
							<p class="media-heading">
							<strong>Cartoon Animations Segmentation and Vectorization ßased on Canny Optimization</strong><br>
							<strong>Ruilong Li</strong>, Yuan Liang, Song-Hai Zhang, <i>Computer Science(《计算机科学》) 2017</i>
							<a target="_blank" href="http://www.cnki.com.cn/Article/CJFDTotal-JSJA201708005.htm">[Paper]</a> 
							<!-- <a target="_blank" href="">[Code]</a> -->
							</p>
							<p class="abstract-text">
							Vectorization of Image/Video has many potential advantages comparing to a raster format, such as higher compression ratios for storage and allowing display on devices with differing capabilities. Cartoon animations are more suitable for vectorizing than the videos from real world because their clear edge and region. We proposed a new algorithm of image segmentation based on Canny operator. We solved the problem of discontinuity of edge detection. We created a material box for each cartoon animation. We proposed a way to low the compression ratio by reuse the material of cartoon in the material box. We also solved the problem of flicker during the vectorization with the material box. We made a system to fully automatic vectorize the cartoon animations includ-ing the shot segmentation, active region extraction and creating the material box. Our system can give good result on different kinds of cartoon, even those with complex texture in it.
							</p>
							</div>
							</div>

							<!-- project -->

						<div class="col-md-1 column">
						</div>
					</div>
				</div>
			</div>
		</div>

		<!-- Bootstrap core JavaScript
		================================================== -->
		<!-- Placed at the end of the document so the pages load faster -->
		<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
		<script>window.jQuery || document.write('<script src="../../assets/js/vendor/jquery.min.js"><\/script>')</script>
		<script src="js/bootstrap.min.js"></script>
		<script src="assets/js/docs.min.js"></script>
		<!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
		<script src="assets/js/ie10-viewport-bug-workaround.js"></script>
	</body>
</html>
